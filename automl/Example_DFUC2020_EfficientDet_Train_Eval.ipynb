{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Example_DFUC2020_EfficientDet_Train_Eval.ipynb","provenance":[{"file_id":"https://github.com/google/automl/blob/master/efficientdet/tutorial.ipynb","timestamp":1594423967708}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"hGL97-GXjSUw","colab":{},"executionInfo":{"status":"ok","timestamp":1595709522618,"user_tz":240,"elapsed":44807,"user":{"displayName":"Reza Basiri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0USSKZtYCAtISB0hjlk0pCU0HxT5KVtNiF04Z8A=s64","userId":"06086156326319932591"}}},"source":["%%capture\n","#@title\n","import os\n","import sys\n","import tensorflow.compat.v1 as tf\n","\n","# Download source code.\n","if \"efficientdet\" not in os.getcwd():\n","  !git clone --depth 1 https://github.com/rezabasiri/EfficientDetDFU\n","  os.chdir('EfficientDetDFU/automl/efficientdet')\n","  sys.path.append('.')\n","  !pip install -r requirements.txt\n","  !pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n","else:\n","  !git pull"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tow-ic7H3d7i","colab_type":"code","colab":{}},"source":["ckpt = '20200715_DFU2020_ckpt'\n","MODEL = 'efficientdet-d1'\n","\n","def download(m):\n","  if m not in os.listdir():\n","    !curl -c /tmp/cookies \"https://drive.google.com/uc?export=download&id=11L4jYRgCBUzchWt35SOMc2v_dmgZdxat\" > /tmp/intermezzo.html\n","    !curl -L -b /tmp/cookies \"https://drive.google.com$(cat /tmp/intermezzo.html | grep -Po 'uc-download-link\" [^>]* href=\"\\K[^\"]*' | sed 's/\\&amp;/\\&/g')\" > FINAL_DOWNLOADED_FILENAME.zip\n","    !unzip FINAL_DOWNLOADED_FILENAME.zip\n","    !rm -rf FINAL_DOWNLOADED_FILENAME.zip\n","  ckpt_path = os.path.join(os.getcwd(), m)\n","  return ckpt_path\n","\n","# Download checkpoint.\n","ckpt_path = download(ckpt)\n","print('Use ckpt in {}'.format(ckpt_path))\n","\n","# Alternatively access the checkpoint at https://drive.google.com/file/d/11L4jYRgCBUzchWt35SOMc2v_dmgZdxat/view?usp=sharing"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C98Ye0MEyuKD","colab_type":"text"},"source":["## Prepare data"]},{"cell_type":"code","metadata":{"id":"Pp1qGjbgsq3A","colab_type":"code","colab":{}},"source":["# Prepare Training Data\n","!rm -rf *.zip *.tar tfrecord/ val2017/\n","!mkdir tfrecord\n","!PYTHONPATH=\".:$PYTHONPATH\"  python dataset/create_coco_tfrecord.py \\\n","      --image_dir=\"{/Path/To/Train/Images}\" \\\n","      --object_annotations_file=\"/Path/To/TrainAnnotation/instances_Images.json\" \\\n","      --output_file_prefix=tfrecord/testdev \\\n","      --num_shards=15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WXB7Vsm-yiRk","colab_type":"code","colab":{}},"source":["# Prepare Validation Data\n","!PYTHONPATH=\".:$PYTHONPATH\"  python dataset/create_coco_tfrecord.py \\\n","      --image_dir=\"{/Path/To/Val/Images}\" \\\n","      --object_annotations_file=\"/Path/To/ValAnnotation/instances_ImagesVal.json\" \\\n","      --output_file_prefix=tfrecord/Valdev \\\n","      --num_shards=15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6PC6QrMlylOF","colab_type":"code","colab":{}},"source":["file_pattern = 'testdev-*-of-00015.tfrecord' # Update to match the number of shards for training set\n","file_patternVal = 'Valdev-*-of-00015.tfrecord' # Update to match the number of shards for valid set\n","\n","images_per_epoch = 57 * len(tf.io.gfile.glob('tfrecord/' + file_pattern))\n","images_per_epoch = images_per_epoch // 8 * 8  # round to 64.\n","\n","images_per_epochVal = 57 * len(tf.io.gfile.glob('tfrecord/' + file_patternVal))\n","images_per_epochVal = images_per_epochVal // 8 * 8  # round to 64.\n","\n","print('images_per_epoch = {}'.format(images_per_epoch))\n","print('images_per_epochVal = {}'.format(images_per_epochVal))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SD59rsZJc1WW","colab_type":"code","colab":{}},"source":["# generating train tfrecord is large, so we skip the execution here.\n","import os\n","\n","!mkdir model_dir/\n","# key option: use --ckpt rather than --backbone_ckpt.\n","!python main.py --mode=train_and_eval \\\n","    --training_file_pattern=tfrecord/{file_pattern} \\\n","    --validation_file_pattern=tfrecord/{file_patternVal} \\\n","    --model_name={MODEL} \\\n","    --model_dir=model_dir/{MODEL}-finetune \\\n","    --ckpt= {ckpt} \\\n","    --train_batch_size=8 \\\n","    --eval_batch_size=8 --eval_samples={images_per_epochVal}  \\\n","    --num_examples_per_epoch={images_per_epoch}  --num_epochs=2  \\\n","    --hparams=\"num_classes=2,max_instances_per_image=5,learning_rate=0.001,moving_average_decay=0,mixed_precision=true,use_augmix=True\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUK3s2d84R7x","colab_type":"code","colab":{}},"source":["%load_ext tensorboard\n","%tensorboard --logdir model_dir/\n","# Notably, this is just a demo with almost zero accuracy due to very limited\n","# training steps, but we can see finetuning has smaller loss than training\n","# from scratch at the begining."],"execution_count":null,"outputs":[]}]}